{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installar pip isntall psycopg2-binary\n",
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insertar csv a postgresql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>production_family</th>\n",
       "      <th>wk</th>\n",
       "      <th>fecha</th>\n",
       "      <th>fa_pn</th>\n",
       "      <th>pn_componente</th>\n",
       "      <th>wo</th>\n",
       "      <th>quantity</th>\n",
       "      <th>cod_defecto</th>\n",
       "      <th>label</th>\n",
       "      <th>linea</th>\n",
       "      <th>turno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>48404</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>1</td>\n",
       "      <td>D1093</td>\n",
       "      <td>1</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>48414</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DO085</td>\n",
       "      <td>1</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>48416</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DO1646</td>\n",
       "      <td>1</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>49697</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>4</td>\n",
       "      <td>DO1644</td>\n",
       "      <td>1</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>20363</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  production_family       wk     fecha  fa_pn pn_componente         wo  \\\n",
       "0     Wands (Kamuk)  Week 01  1/3/2020  48400         48404  2046690.0   \n",
       "1     Wands (Kamuk)  Week 01  1/3/2020  48400         48414  2046690.0   \n",
       "2     Wands (Kamuk)  Week 01  1/3/2020  48400         48416  2046690.0   \n",
       "3     Wands (Kamuk)  Week 01  1/3/2020  48400         49697  2046690.0   \n",
       "4     Wands (Kamuk)  Week 01  1/3/2020  48400         20363  2046690.0   \n",
       "\n",
       "   quantity cod_defecto  label    linea turno  \n",
       "0         1       D1093      1  Line 13    T1  \n",
       "1         1       DO085      1  Line 13   T 1  \n",
       "2         1      DO1646      1  Line 13   T 1  \n",
       "3         4      DO1644      1  Line 13   T 1  \n",
       "4         4         NaN      0  Line 13   T 1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./scrap_data_final.csv', encoding='latin-1',sep = ';')\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "production_family     object\n",
       "wk                    object\n",
       "fecha                 object\n",
       "fa_pn                 object\n",
       "pn_componente         object\n",
       "wo                   float64\n",
       "quantity               int64\n",
       "cod_defecto           object\n",
       "label                  int64\n",
       "linea                 object\n",
       "turno                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correr desde aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DROP TABLE IF EXISTS bigdata.scrap;         CREATE TABLE bigdata.scrap        (        production_family varchar(256),wk varchar(256), fecha varchar(256), fa_pn varchar(256), pn_componente varchar(256), wo varchar(256),       quantity float, cod_defecto varchar(256), label integer, linea varchar(256), turno varchar(256)    ); commit;'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_query = 'DROP TABLE IF EXISTS bigdata.scrap;\\\n",
    "         CREATE TABLE bigdata.scrap\\\n",
    "        (\\\n",
    "        production_family varchar(256),wk varchar(256), fecha varchar(256), fa_pn varchar(256), pn_componente varchar(256), wo varchar(256),\\\n",
    "       quantity float, cod_defecto varchar(256), label integer, linea varchar(256), turno varchar(256)\\\n",
    "    ); \\\n",
    "commit;' \n",
    "create_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = psycopg2.connect( host='localhost', user='postgres', password='root', dbname='postgres', port = 5432 )\n",
    "cursor=con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('delete from bigdata.scrap; commit;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(create_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>production_family</th>\n",
       "      <th>wk</th>\n",
       "      <th>fecha</th>\n",
       "      <th>fa_pn</th>\n",
       "      <th>pn_componente</th>\n",
       "      <th>wo</th>\n",
       "      <th>quantity</th>\n",
       "      <th>cod_defecto</th>\n",
       "      <th>label</th>\n",
       "      <th>linea</th>\n",
       "      <th>turno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [production_family, wk, fecha, fa_pn, pn_componente, wo, quantity, cod_defecto, label, linea, turno]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('select * from bigdata.scrap', con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scrap_data_final.csv', 'r') as f:\n",
    "# Notice that we don't need the `csv` module.\n",
    "    next(f) # Skip the header row.\n",
    "    cursor.copy_from(f, 'bigdata.scrap', sep=';')\n",
    "    con.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>production_family</th>\n",
       "      <th>wk</th>\n",
       "      <th>fecha</th>\n",
       "      <th>fa_pn</th>\n",
       "      <th>pn_componente</th>\n",
       "      <th>wo</th>\n",
       "      <th>quantity</th>\n",
       "      <th>cod_defecto</th>\n",
       "      <th>label</th>\n",
       "      <th>linea</th>\n",
       "      <th>turno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>48404</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D1093</td>\n",
       "      <td>1</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>48414</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DO085</td>\n",
       "      <td>1</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>48416</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DO1646</td>\n",
       "      <td>1</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>49697</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>DO1644</td>\n",
       "      <td>1</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>20363</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19922</th>\n",
       "      <td>SA</td>\n",
       "      <td>Week 04</td>\n",
       "      <td>1/26/2020</td>\n",
       "      <td>16358</td>\n",
       "      <td>7229</td>\n",
       "      <td>2049249.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DW07</td>\n",
       "      <td>1</td>\n",
       "      <td>Returns</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19923</th>\n",
       "      <td>SA</td>\n",
       "      <td>Week 04</td>\n",
       "      <td>1/26/2020</td>\n",
       "      <td>93846</td>\n",
       "      <td>42003</td>\n",
       "      <td>2048805.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DW01</td>\n",
       "      <td>1</td>\n",
       "      <td>SA</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19924</th>\n",
       "      <td>SA</td>\n",
       "      <td>Week 04</td>\n",
       "      <td>1/26/2020</td>\n",
       "      <td>93846</td>\n",
       "      <td>4496</td>\n",
       "      <td>2048805.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>SA</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19925</th>\n",
       "      <td>SA</td>\n",
       "      <td>Week 04</td>\n",
       "      <td>1/26/2020</td>\n",
       "      <td>93846</td>\n",
       "      <td>12533</td>\n",
       "      <td>2048805.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>SA</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19926</th>\n",
       "      <td>SA</td>\n",
       "      <td>Week 04</td>\n",
       "      <td>1/26/2020</td>\n",
       "      <td>93846</td>\n",
       "      <td>42002</td>\n",
       "      <td>2048805.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>SA</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19927 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      production_family       wk      fecha  fa_pn pn_componente         wo  \\\n",
       "0         Wands (Kamuk)  Week 01   1/3/2020  48400         48404  2046690.0   \n",
       "1         Wands (Kamuk)  Week 01   1/3/2020  48400         48414  2046690.0   \n",
       "2         Wands (Kamuk)  Week 01   1/3/2020  48400         48416  2046690.0   \n",
       "3         Wands (Kamuk)  Week 01   1/3/2020  48400         49697  2046690.0   \n",
       "4         Wands (Kamuk)  Week 01   1/3/2020  48400         20363  2046690.0   \n",
       "...                 ...      ...        ...    ...           ...        ...   \n",
       "19922                SA  Week 04  1/26/2020  16358          7229  2049249.0   \n",
       "19923                SA  Week 04  1/26/2020  93846         42003  2048805.0   \n",
       "19924                SA  Week 04  1/26/2020  93846          4496  2048805.0   \n",
       "19925                SA  Week 04  1/26/2020  93846         12533  2048805.0   \n",
       "19926                SA  Week 04  1/26/2020  93846         42002  2048805.0   \n",
       "\n",
       "       quantity cod_defecto  label    linea turno  \n",
       "0           1.0       D1093      1  Line 13    T1  \n",
       "1           1.0       DO085      1  Line 13   T 1  \n",
       "2           1.0      DO1646      1  Line 13   T 1  \n",
       "3           4.0      DO1644      1  Line 13   T 1  \n",
       "4           4.0                  0  Line 13   T 1  \n",
       "...         ...         ...    ...      ...   ...  \n",
       "19922       3.0        DW07      1  Returns   T 1  \n",
       "19923       8.0        DW01      1       SA   T 1  \n",
       "19924       6.0                  0       SA   T 1  \n",
       "19925       6.0                  0       SA   T 1  \n",
       "19926       6.0                  0       SA   T 1  \n",
       "\n",
       "[19927 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('select * from bigdata.scrap', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aqui ya se conecta con pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, date_format, udf \n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Basic JDBC pipeline\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"./postgresql-42.2.8.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"./postgresql-42.2.8.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Reading single DataFrame in Spark by retrieving all rows from a DB table.\n",
    "df = spark \\\n",
    "    .read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"root\") \\\n",
    "    .option(\"dbtable\", \"bigdata.scrap\")\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+--------+-----+-------------+---------+--------+-----------+--------------------+-------+-----+\n",
      "|production_family|     wk|   fecha|fa_pn|pn_componente|       wo|quantity|cod_defecto|               causa|  linea|turno|\n",
      "+-----------------+-------+--------+-----+-------------+---------+--------+-----------+--------------------+-------+-----+\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        48404|2046690.0|     1.0|      D1093|          C7-Proceso|Line 13|   T1|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        48414|2046690.0|     1.0|      DO085|          C7-Proceso|Line 13|  T 1|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        48416|2046690.0|     1.0|     DO1646|          C7-Proceso|Line 13|  T 1|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        49697|2046690.0|     4.0|     DO1644|          C7-Proceso|Line 13|  T 1|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        20363|2046690.0|     4.0|           |C17- Pruebas de c...|Line 13|  T 1|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        20363|2046690.0|    10.0|           |C11 - Material af...|Line 13|  T 1|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        26922|2046690.0|     4.0|           |C17- Pruebas de c...|Line 13|  T 1|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        26922|2046690.0|     6.0|     PKG119|          C7-Proceso|Line 13|  T 1|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        26922|2046690.0|     4.0|     PKG105|          C7-Proceso|Line 13|  T 1|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        26922|2046692.0|     1.0|           |C17- Pruebas de c...|Line 13|  T 2|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        20363|2046692.0|     4.0|           |C17- Pruebas de c...|Line 13|  T 2|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        26922|2046692.0|     1.0|     PKG119|          C7-Proceso|Line 13|  T 2|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        20363|2046692.0|     1.0|           |C11 - Material af...|Line 13|  T 2|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        49697|2046692.0|     1.0|           |          C7-Proceso|Line 13|  T 2|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        26922|2046691.0|     4.0|           |C17- Pruebas de c...|Line 13|  T 2|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        20363|2046691.0|     4.0|           |C17- Pruebas de c...|Line 13|  T 2|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        26922|2046691.0|     4.0|     PKG119|          C7-Proceso|Line 13|  T 2|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        20363|2046691.0|    10.0|           |C11 - Material af...|Line 13|  T 2|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        26922|2046691.0|     6.0|     PKG111|                    |Line 13|  T 2|\n",
      "|    Wands (Kamuk)|Week 01|1/3/2020|48400|        49697|2046691.0|     4.0|     DO1643|          C7-Proceso|Line 13|  T 2|\n",
      "+-----------------+-------+--------+-----+-------------+---------+--------+-----------+--------------------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargo los archivos, si postgres "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudio de Scrap: Empresa Smith and Nephew 2020\n",
    "\n",
    "Con la finalidad de entender el comportamiento del scrap en del 2020, la empresa Smith and Nephew CR. Establecio un recuento del scrap por modo de falla. Dado que la cantidad de fallos que generan scrap es muy amplia, se priorizo determinar el scrap producido por fallos de proceso, dado que el historico de datos del 2019 mostro todos los fallos de proceso se debian por fallos en la validacion de proceso. \n",
    "La correccion de este tipo de fallos implican una amplia inversion de la empresa, por lo que es de interese predecir cuando una familia de productos genera fallos por proceso, al la vez que se relaciona el impacto de los turnos y la linea en cada fallo. \n",
    "\n",
    "El set de datos obtenidos para el proyecto equivale a todo el desecho realizado en la empresa por linea durante el mes de enero del 2020, como parte del proyecto piloto para poder predecir desgastes en las condiciones validadas en las lineas de producion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informacion en el set de datos: \n",
    "- production_family: Familia de productos, los productos se dividen segun su mercado y este es un indicador de la ganancia final.\n",
    "- wk: Semana en la que se documento el scrap, la produccion se planea por semanas. Categorico \n",
    "- fecha: fecha en la que se registro el scrap. Categorico\n",
    "- fa_pn: Numero de parte del producto final en el que se detecto el scrap.Categorico \n",
    "- pn_componente: Numero de parte del componente desechado.Categorico \n",
    "- wo: Order de produccion en la cual se detecto el scrap.Categorico \n",
    "- quantity: cantidad de unidades desechadas. Numerico\n",
    "- cod_defecto: condigo de defecto registrado.Categorico \n",
    "- label: Es la causa de fallo, para este estudio piloto se designo como label. 1 es un fallo por proceso, 0 cualquier otro fallo. Categorico ( Trasformado en binario)\n",
    "- linea: de produccion en la que se realizo el fallo. Categorico \n",
    "- turno: Turno de produccion, con o sin extras en el que se registro el fallo.Categorico \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, date_format, udf \n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"scrap_data\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"./postgresql-42.2.8.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"./postgresql-42.2.8.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Reading single DataFrame in Spark by retrieving all rows from a DB table.\n",
    "df = spark \\\n",
    "    .read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"root\") \\\n",
    "    .option(\"dbtable\", \"bigdata.scrap\")\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploracion de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuantos datos se tienen y el numero de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19927, 11)\n"
     ]
    }
   ],
   "source": [
    "#check the shape of the data \n",
    "print((df.count(),len(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El esquema del set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- production_family: string (nullable = true)\n",
      " |-- wk: string (nullable = true)\n",
      " |-- fecha: string (nullable = true)\n",
      " |-- fa_pn: string (nullable = true)\n",
      " |-- pn_componente: string (nullable = true)\n",
      " |-- wo: string (nullable = true)\n",
      " |-- quantity: double (nullable = true)\n",
      " |-- cod_defecto: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- linea: string (nullable = true)\n",
      " |-- turno: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printSchema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificacion de las calumnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['production_family',\n",
       " 'wk',\n",
       " 'fecha',\n",
       " 'fa_pn',\n",
       " 'pn_componente',\n",
       " 'wo',\n",
       " 'quantity',\n",
       " 'cod_defecto',\n",
       " 'label',\n",
       " 'linea',\n",
       " 'turno']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of columns in dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizacion del set de datos, las primeras 5 lineas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>production_family</th>\n",
       "      <th>wk</th>\n",
       "      <th>fecha</th>\n",
       "      <th>fa_pn</th>\n",
       "      <th>pn_componente</th>\n",
       "      <th>wo</th>\n",
       "      <th>quantity</th>\n",
       "      <th>cod_defecto</th>\n",
       "      <th>label</th>\n",
       "      <th>linea</th>\n",
       "      <th>turno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>48404</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>1</td>\n",
       "      <td>D1093</td>\n",
       "      <td>1</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>48414</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DO085</td>\n",
       "      <td>1</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>48416</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DO1646</td>\n",
       "      <td>1</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>49697</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>4</td>\n",
       "      <td>DO1644</td>\n",
       "      <td>1</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wands (Kamuk)</td>\n",
       "      <td>Week 01</td>\n",
       "      <td>1/3/2020</td>\n",
       "      <td>48400</td>\n",
       "      <td>20363</td>\n",
       "      <td>2046690.0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>Line 13</td>\n",
       "      <td>T 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  production_family       wk     fecha  fa_pn pn_componente         wo  \\\n",
       "0     Wands (Kamuk)  Week 01  1/3/2020  48400         48404  2046690.0   \n",
       "1     Wands (Kamuk)  Week 01  1/3/2020  48400         48414  2046690.0   \n",
       "2     Wands (Kamuk)  Week 01  1/3/2020  48400         48416  2046690.0   \n",
       "3     Wands (Kamuk)  Week 01  1/3/2020  48400         49697  2046690.0   \n",
       "4     Wands (Kamuk)  Week 01  1/3/2020  48400         20363  2046690.0   \n",
       "\n",
       "   quantity cod_defecto  label    linea turno  \n",
       "0         1       D1093      1  Line 13    T1  \n",
       "1         1       DO085      1  Line 13   T 1  \n",
       "2         1      DO1646      1  Line 13   T 1  \n",
       "3         4      DO1644      1  Line 13   T 1  \n",
       "4         4        None      0  Line 13   T 1  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------+---------+--------------------+--------------------+------------------+------------------+-----------+------------------+-------------+-----+\n",
      "|summary|production_family|     wk|    fecha|               fa_pn|       pn_componente|                wo|          quantity|cod_defecto|             label|        linea|turno|\n",
      "+-------+-----------------+-------+---------+--------------------+--------------------+------------------+------------------+-----------+------------------+-------------+-----+\n",
      "|  count|            19927|  19927|    19927|               19918|               19855|             19912|             19927|      11476|             19927|        19927|19927|\n",
      "|   mean|             null|   null|     null|1.5052684017250178E7|3.0355238520430107E7|2065847.6619124147|17.262457971596326|       null|0.3141466352185477|         null| null|\n",
      "| stddev|             null|   null|     null|2.9612881848654352E7| 3.069515495343108E8| 598355.0758189503|158.75686382624394|       null| 0.464186750924247|         null| null|\n",
      "|    min|           Final |Week 01|1/10/2020|            04351-02|            04351-02|          204660.0|                 1|       #N01|                 0|      Ambient|  T 1|\n",
      "|    max|    Wands (Kamuk)|Week 05| 1/9/2020|              MR3557|              rr 633|       2.5048045E7|             18000|      sm701|                 1|Suture Cutler|   T3|\n",
      "+-------+-----------------+-------+---------+--------------------+--------------------+------------------+------------------+-----------+------------------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exploratory Data Analysis\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificacion del total de fallos encontrados por proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1| 6260|\n",
      "|    0|13667|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que la causa de scrappor falla de processo (1) es casi una tercera parter de los datos, la cual implica que las linea tienen muchos fallos en el proceso validado. Este tipo de fallos produce grandes perdidas operativas. El objetivo del estidio es predecir cuando va a fallar una familia de productos por una condicion de validacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables a considerar en el estudio.\n",
    "\n",
    "El alcance selecionado para este estudio es analizar el impacto del scrap por proceso por familia de productos, turno y linea. Esto debido a la cantidad de datos, posterior a este estudio se recopilaran datos para unir el impacto por componente y por producto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|production_family|count|\n",
      "+-----------------+-----+\n",
      "|             Opus|10658|\n",
      "|           Final | 3891|\n",
      "|               SA|   24|\n",
      "|              PKG| 1591|\n",
      "|    Wands (Kamuk)| 3035|\n",
      "|      Rapid Rhino|  728|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Contar las categorias de familias de productos\n",
    "df.groupBy('production_family').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|turno|count|\n",
      "+-----+-----+\n",
      "|   T3|  222|\n",
      "|  T 1|10912|\n",
      "|   T1|    3|\n",
      "|  T 2| 8790|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Contar las categorias de turno\n",
    "df.groupBy('turno').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|           Linea|count|\n",
      "+----------------+-----+\n",
      "|   Line 6 (Evac)| 1723|\n",
      "|       Multiwire|   50|\n",
      "|         Line 13|  735|\n",
      "|Line 17 (Vulcan)|  174|\n",
      "|         Returns|   66|\n",
      "|         Line 14|  424|\n",
      "|            Flow|    2|\n",
      "|  Line 16 (Echo)|  972|\n",
      "|              SA|  278|\n",
      "|         Ambient|   25|\n",
      "|   LINE 11 (EPX)|  728|\n",
      "|             PKG| 1591|\n",
      "|          Linea9| 1919|\n",
      "|         Line 15|  742|\n",
      "|  Line 3 (Pilot)|  541|\n",
      "|           Laser|  210|\n",
      "| Line 7 (Reflex)| 1176|\n",
      "|    Line 2 (STV)|  523|\n",
      "|          Line 4| 2136|\n",
      "|   Line 5 (SMX2)| 1498|\n",
      "+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Contar las categorias de turno\n",
    "df.groupBy('Linea').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada condicion de turno es diferente: Para efectos del estudio T3 es turno nocturno, T 1 es turno 1 con gente en extras, T1 sin gente en extras, T 2 es turno 2 con gente en extras y T2 con gente sin extras, en el periodo que se esta estudiando en el turno 2 no hay extras. Los turnos igualmente son un atributo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformar los datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que la causa es la salida y es un atributo,  familia de productos, linea y turno es un atributo, y son los  feature de relevancia se requiere una trasnformacion de tipo One Hot Encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "turno_indexer = StringIndexer(inputCol=\"turno\", outputCol=\"turno_index\").fit(df)\n",
    "df = turno_indexer.transform(df)\n",
    "turno_encoder = OneHotEncoder(inputCol=\"turno_index\", outputCol=\"turno_purpose_vec\")\n",
    "df = turno_encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-----------------+\n",
      "|turno|turno_index|turno_purpose_vec|\n",
      "+-----+-----------+-----------------+\n",
      "|T1   |3.0        |(3,[],[])        |\n",
      "|T 1  |0.0        |(3,[0],[1.0])    |\n",
      "|T 1  |0.0        |(3,[0],[1.0])    |\n",
      "|T 1  |0.0        |(3,[0],[1.0])    |\n",
      "|T 1  |0.0        |(3,[0],[1.0])    |\n",
      "|T 1  |0.0        |(3,[0],[1.0])    |\n",
      "|T 1  |0.0        |(3,[0],[1.0])    |\n",
      "|T 1  |0.0        |(3,[0],[1.0])    |\n",
      "|T 1  |0.0        |(3,[0],[1.0])    |\n",
      "|T 2  |1.0        |(3,[1],[1.0])    |\n",
      "|T 2  |1.0        |(3,[1],[1.0])    |\n",
      "|T 2  |1.0        |(3,[1],[1.0])    |\n",
      "|T 2  |1.0        |(3,[1],[1.0])    |\n",
      "|T 2  |1.0        |(3,[1],[1.0])    |\n",
      "|T 2  |1.0        |(3,[1],[1.0])    |\n",
      "|T 2  |1.0        |(3,[1],[1.0])    |\n",
      "|T 2  |1.0        |(3,[1],[1.0])    |\n",
      "|T 2  |1.0        |(3,[1],[1.0])    |\n",
      "|T 2  |1.0        |(3,[1],[1.0])    |\n",
      "|T 2  |1.0        |(3,[1],[1.0])    |\n",
      "+-----+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['turno','turno_index','turno_purpose_vec']).show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_family_indexer = StringIndexer(inputCol=\"production_family\", outputCol=\"production_family_index\").fit(df)\n",
    "df = production_family_indexer.transform(df)\n",
    "production_family_encoder = OneHotEncoder(inputCol=\"production_family_index\", outputCol=\"production_family_purpose_vec\")\n",
    "df = production_family_encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------------+-----------------------------+\n",
      "|production_family|production_family_index|production_family_purpose_vec|\n",
      "+-----------------+-----------------------+-----------------------------+\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "|Wands (Kamuk)    |2.0                    |(5,[2],[1.0])                |\n",
      "+-----------------+-----------------------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['production_family','production_family_index','production_family_purpose_vec']).show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "linea_indexer = StringIndexer(inputCol=\"linea\", outputCol=\"linea_index\").fit(df)\n",
    "df = linea_indexer.transform(df)\n",
    "linea_encoder = OneHotEncoder(inputCol=\"linea_index\", outputCol=\"linea_purpose_vec\")\n",
    "df = linea_encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----------------+\n",
      "|linea  |linea_index|linea_purpose_vec|\n",
      "+-------+-----------+-----------------+\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "|Line 13|10.0       |(24,[10],[1.0])  |\n",
      "+-------+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['linea','linea_index','linea_purpose_vec']).show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usamos \"VectorAssembler\" para crear un único vector de features y clase, para ser usado por nuestro modelo de entrenamiento:\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['production_family',\n",
       " 'wk',\n",
       " 'fecha',\n",
       " 'fa_pn',\n",
       " 'pn_componente',\n",
       " 'wo',\n",
       " 'quantity',\n",
       " 'cod_defecto',\n",
       " 'label',\n",
       " 'linea',\n",
       " 'turno',\n",
       " 'turno_index',\n",
       " 'turno_purpose_vec',\n",
       " 'production_family_index',\n",
       " 'production_family_purpose_vec',\n",
       " 'linea_index',\n",
       " 'linea_purpose_vec']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembler = VectorAssembler(inputCols=['turno_purpose_vec','production_family_purpose_vec', 'linea_purpose_vec'], outputCol=\"features\")\n",
    "df = df_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- production_family: string (nullable = true)\n",
      " |-- wk: string (nullable = true)\n",
      " |-- fecha: string (nullable = true)\n",
      " |-- fa_pn: string (nullable = true)\n",
      " |-- pn_componente: string (nullable = true)\n",
      " |-- wo: double (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- cod_defecto: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- linea: string (nullable = true)\n",
      " |-- turno: string (nullable = true)\n",
      " |-- turno_index: double (nullable = false)\n",
      " |-- turno_purpose_vec: vector (nullable = true)\n",
      " |-- production_family_index: double (nullable = false)\n",
      " |-- production_family_purpose_vec: vector (nullable = true)\n",
      " |-- linea_index: double (nullable = false)\n",
      " |-- linea_purpose_vec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-----+\n",
      "|features                   |label|\n",
      "+---------------------------+-----+\n",
      "|(32,[5,18],[1.0,1.0])      |1    |\n",
      "|(32,[0,5,18],[1.0,1.0,1.0])|1    |\n",
      "|(32,[0,5,18],[1.0,1.0,1.0])|1    |\n",
      "|(32,[0,5,18],[1.0,1.0,1.0])|1    |\n",
      "|(32,[0,5,18],[1.0,1.0,1.0])|0    |\n",
      "|(32,[0,5,18],[1.0,1.0,1.0])|0    |\n",
      "|(32,[0,5,18],[1.0,1.0,1.0])|0    |\n",
      "|(32,[0,5,18],[1.0,1.0,1.0])|1    |\n",
      "|(32,[0,5,18],[1.0,1.0,1.0])|1    |\n",
      "|(32,[1,5,18],[1.0,1.0,1.0])|0    |\n",
      "|(32,[1,5,18],[1.0,1.0,1.0])|0    |\n",
      "|(32,[1,5,18],[1.0,1.0,1.0])|1    |\n",
      "|(32,[1,5,18],[1.0,1.0,1.0])|0    |\n",
      "|(32,[1,5,18],[1.0,1.0,1.0])|1    |\n",
      "|(32,[1,5,18],[1.0,1.0,1.0])|0    |\n",
      "|(32,[1,5,18],[1.0,1.0,1.0])|0    |\n",
      "|(32,[1,5,18],[1.0,1.0,1.0])|1    |\n",
      "|(32,[1,5,18],[1.0,1.0,1.0])|0    |\n",
      "|(32,[1,5,18],[1.0,1.0,1.0])|0    |\n",
      "|(32,[1,5,18],[1.0,1.0,1.0])|1    |\n",
      "+---------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['features','label']).show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df=df.select(['features','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data \n",
    "training_df,test_df = model_df.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14940"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1| 4719|\n",
      "|    0|10221|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4987"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1| 1541|\n",
      "|    0| 3446|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística.\n",
    "\n",
    "La regresión logística es un tipo de análisis de regresión utilizado para predecir el resultado de una variable categórica (una variable que puede adoptar un número limitado de categorías)  en función de las variables independientes o predictoras. Dado que el tipo de defecto es una varible categorica (Proceso, paro de maquina, error de operario...) lo mas optimo es iniciar con esta regresion en primera instancia.\n",
    " \n",
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg=LogisticRegression().fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_summary=log_reg.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7151271753681392"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_summary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7675459441075684"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7136614370656924, 0.7359836901121305]\n"
     ]
    }
   ],
   "source": [
    "print(lr_summary.precisionByLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9746600136972899, 0.15299851663488026]\n"
     ]
    }
   ],
   "source": [
    "print(lr_summary.recallByLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(32,[0,3],[1.0,1.0])|    0|[0.99931135577201...|[0.73092316141517...|       0.0|\n",
      "|(32,[0,3],[1.0,1.0])|    1|[0.99931135577201...|[0.73092316141517...|       0.0|\n",
      "|(32,[0,3,8],[1.0,...|    0|[4.67003104270878...|[0.99071503985679...|       0.0|\n",
      "|(32,[0,3,8],[1.0,...|    0|[4.67003104270878...|[0.99071503985679...|       0.0|\n",
      "|(32,[0,3,8],[1.0,...|    0|[4.67003104270878...|[0.99071503985679...|       0.0|\n",
      "|(32,[0,3,8],[1.0,...|    0|[4.67003104270878...|[0.99071503985679...|       0.0|\n",
      "|(32,[0,3,8],[1.0,...|    0|[4.67003104270878...|[0.99071503985679...|       0.0|\n",
      "|(32,[0,3,8],[1.0,...|    0|[4.67003104270878...|[0.99071503985679...|       0.0|\n",
      "|(32,[0,3,8],[1.0,...|    0|[4.67003104270878...|[0.99071503985679...|       0.0|\n",
      "|(32,[0,3,8],[1.0,...|    0|[4.67003104270878...|[0.99071503985679...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = log_reg.transform(test_df)\n",
    "predictions.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = log_reg.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = log_reg.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7166633246440746"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7126280106025605"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions.weightedPrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9724318049912942, 0.14471122647631407]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions.recallByLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.717712572285286, 0.7012578616352201]\n"
     ]
    }
   ],
   "source": [
    "print(model_predictions.precisionByLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7595613494263774"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions.areaUnderROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El testing predice en un 0.7136614370656924  mientras que el modelo predice en un 0.717712572285286 por lo que el modelo se considera optimo para el estudio en cuestion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el metodo de random forest es muy poderoso con datos con multiples categorias, por lo que se espera un buen resultado con su aplicacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = rf_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los parámetros a probar se selecciona **maxDepth**, **maxBins** y **numTrees**, se aplica cross-validation para determinar el mejor modelo y se usa además five-fold cross-validation (4 partes para entrenamiento y 1 para testing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparametros utilizados\n",
    "- Para iniciar se van a utilizar los mismos parametros de referencia utilizados en el ejemplo del curos: \n",
    "        maxDepth [5,10,20,25,30] , maxBins [20,30,40 ] y numTrees [5, 20,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 10.38 min / 622.96 sec\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import time\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.maxDepth, [5,10,20,25,30])\n",
    "             .addGrid(rf.maxBins, [20,30,40 ])\n",
    "             .addGrid(rf.numTrees, [5, 20,50])\n",
    "             .build())\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "cv_model = cv.fit(training_df)\n",
    "\n",
    "end = time.time()\n",
    "m = (end - start)/60\n",
    "m = round(m, 2)\n",
    "s = (end - start)\n",
    "s = round(s, 2)\n",
    "print(f\"Time: {m} min / {s} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for entire dataset\n",
    "model_predictions = best_rf_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos=model_predictions.filter(model_predictions['label']==1).filter(model_predictions['prediction']==1).count()\n",
    "actual_pos=model_predictions.filter(model_predictions['label']==1).count()\n",
    "pred_pos=model_predictions.filter(model_predictions['prediction']==1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14341336794289422"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall \n",
    "float(true_pos)/(actual_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Recall de una clase expresa cuan bien puede el modelo detectar a esa clase. Por lo que un 14% no es un buen valor, es decir que puede diferenciar entre otros fallos y el fallo por validacion en un 14%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7015873015873015"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Precision on test Data \n",
    "float(true_pos)/(pred_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Precisión de una clase define cuan confiable es un modelo en responder si un punto pertenece a esa clase. Un 70% es un buen valor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Al obtenerse un recall muy bajo, se buscara optimizar el modelo para mejorar la prediccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[26.479887605827507, 23.520112394172493]</td>\n",
       "      <td>[0.5295977521165501, 0.47040224788344986]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[26.479887605827507, 23.520112394172493]</td>\n",
       "      <td>[0.5295977521165501, 0.47040224788344986]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  label  \\\n",
       "0   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   \n",
       "1   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      1   \n",
       "2   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "3   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "4   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "5   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "6   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "7   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "8   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "9   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "10  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "11  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "12  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "13  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "14  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "15  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "16  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "17  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "18  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "19  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "\n",
       "                               rawPrediction  \\\n",
       "0   [26.479887605827507, 23.520112394172493]   \n",
       "1   [26.479887605827507, 23.520112394172493]   \n",
       "2    [49.15889353777858, 0.8411064622214095]   \n",
       "3    [49.15889353777858, 0.8411064622214095]   \n",
       "4    [49.15889353777858, 0.8411064622214095]   \n",
       "5    [49.15889353777858, 0.8411064622214095]   \n",
       "6    [49.15889353777858, 0.8411064622214095]   \n",
       "7    [49.15889353777858, 0.8411064622214095]   \n",
       "8    [49.15889353777858, 0.8411064622214095]   \n",
       "9    [49.15889353777858, 0.8411064622214095]   \n",
       "10   [49.15889353777858, 0.8411064622214095]   \n",
       "11   [49.15889353777858, 0.8411064622214095]   \n",
       "12   [49.15889353777858, 0.8411064622214095]   \n",
       "13   [49.15889353777858, 0.8411064622214095]   \n",
       "14   [49.15889353777858, 0.8411064622214095]   \n",
       "15   [49.15889353777858, 0.8411064622214095]   \n",
       "16   [49.15889353777858, 0.8411064622214095]   \n",
       "17   [49.15889353777858, 0.8411064622214095]   \n",
       "18   [49.15889353777858, 0.8411064622214095]   \n",
       "19   [49.15889353777858, 0.8411064622214095]   \n",
       "\n",
       "                                  probability  prediction  \n",
       "0   [0.5295977521165501, 0.47040224788344986]         0.0  \n",
       "1   [0.5295977521165501, 0.47040224788344986]         0.0  \n",
       "2   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "3   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "4   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "5   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "6   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "7   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "8   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "9   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "10  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "11  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "12  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "13  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "14  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "15  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "16  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "17  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "18  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "19  [0.9831778707555717, 0.01682212924442819]         0.0  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions.limit(20).toPandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparametros utilizados modelo 2\n",
    "- Se ajustan a un modelo mas robusto para mejorar el recall\n",
    "        maxDepth [2,4,6,8,10,15,20,25,30] , maxBins [5,10,15,20,25,30,35,40 ] y numTrees [5, 10, 20,30,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 59.67 min / 3580.48 sec\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import time\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.maxDepth, [2,4,6,8,10,15,20,25,30])\n",
    "             .addGrid(rf.maxBins, [5,10,15,20,25,30,35,40 ])\n",
    "             .addGrid(rf.numTrees, [5, 10, 20,30,50])\n",
    "             .build())\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "cv_model = cv.fit(training_df)\n",
    "\n",
    "end = time.time()\n",
    "m = (end - start)/60\n",
    "m = round(m, 2)\n",
    "s = (end - start)\n",
    "s = round(s, 2)\n",
    "print(f\"Time: {m} min / {s} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "best2_rf_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for entire dataset\n",
    "model_predictions = best2_rf_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos=model_predictions.filter(model_predictions['label']==1).filter(model_predictions['prediction']==1).count()\n",
    "actual_pos=model_predictions.filter(model_predictions['label']==1).count()\n",
    "pred_pos=model_predictions.filter(model_predictions['prediction']==1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14341336794289422"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall2 \n",
    "float(true_pos)/(actual_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se mantuvo el 14% en el recall, esto implica que este modelo no va a converger con los datos analizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7015873015873015"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Precision on test Data \n",
    "float(true_pos)/(pred_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[26.479887605827507, 23.520112394172493]</td>\n",
       "      <td>[0.5295977521165501, 0.47040224788344986]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[26.479887605827507, 23.520112394172493]</td>\n",
       "      <td>[0.5295977521165501, 0.47040224788344986]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[49.15889353777858, 0.8411064622214095]</td>\n",
       "      <td>[0.9831778707555717, 0.01682212924442819]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  label  \\\n",
       "0   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   \n",
       "1   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      1   \n",
       "2   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "3   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "4   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "5   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "6   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "7   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "8   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "9   (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "10  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "11  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "12  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "13  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "14  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "15  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "16  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "17  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "18  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "19  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      0   \n",
       "\n",
       "                               rawPrediction  \\\n",
       "0   [26.479887605827507, 23.520112394172493]   \n",
       "1   [26.479887605827507, 23.520112394172493]   \n",
       "2    [49.15889353777858, 0.8411064622214095]   \n",
       "3    [49.15889353777858, 0.8411064622214095]   \n",
       "4    [49.15889353777858, 0.8411064622214095]   \n",
       "5    [49.15889353777858, 0.8411064622214095]   \n",
       "6    [49.15889353777858, 0.8411064622214095]   \n",
       "7    [49.15889353777858, 0.8411064622214095]   \n",
       "8    [49.15889353777858, 0.8411064622214095]   \n",
       "9    [49.15889353777858, 0.8411064622214095]   \n",
       "10   [49.15889353777858, 0.8411064622214095]   \n",
       "11   [49.15889353777858, 0.8411064622214095]   \n",
       "12   [49.15889353777858, 0.8411064622214095]   \n",
       "13   [49.15889353777858, 0.8411064622214095]   \n",
       "14   [49.15889353777858, 0.8411064622214095]   \n",
       "15   [49.15889353777858, 0.8411064622214095]   \n",
       "16   [49.15889353777858, 0.8411064622214095]   \n",
       "17   [49.15889353777858, 0.8411064622214095]   \n",
       "18   [49.15889353777858, 0.8411064622214095]   \n",
       "19   [49.15889353777858, 0.8411064622214095]   \n",
       "\n",
       "                                  probability  prediction  \n",
       "0   [0.5295977521165501, 0.47040224788344986]         0.0  \n",
       "1   [0.5295977521165501, 0.47040224788344986]         0.0  \n",
       "2   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "3   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "4   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "5   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "6   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "7   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "8   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "9   [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "10  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "11  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "12  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "13  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "14  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "15  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "16  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "17  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "18  [0.9831778707555717, 0.01682212924442819]         0.0  \n",
       "19  [0.9831778707555717, 0.01682212924442819]         0.0  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions.limit(20).toPandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo mas adecuado para este estudio es una regresion logistica por los valores obtenidos durante la evaluacion del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
